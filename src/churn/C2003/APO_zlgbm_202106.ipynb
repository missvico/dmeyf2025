{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cEmzeUKFkPh"
   },
   "source": [
    "# Wokflow  **TEST** zLightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DenyKXkiJ5JN"
   },
   "source": [
    "##  Big Picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este workflow es de testeo, hace la predicción final en 202106 el último mes para el cual podemos construir la clase_ternaria completa y por lo tanto medir la ganancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-K2_ZsZGrVD"
   },
   "source": [
    "Se muestra el workflow con la Bayesian Optimization diseñada para que LightGBM maximice la ganancia en pesos argentinos\n",
    "<br> En la Primera Competencia se maximizo la metrica global ROC AUC,  ahora pasamos a la metrica real que llamamos ganancia y que solo se concentra en los  11000 registros con mayor probabilidad de  {\"BAJA+1\",\"BAJA+2\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intencionalmente este notebook es un *semi-esqueleto*  al que usted deberá completar reutilizando código que ya generó para la Primera Competencia y nuevo código que resuelva las problemáticas presentes en esta competencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-12 16:59:06 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td>  2022680</td><td> 108.1</td><td>   3608172</td><td>  192.7</td><td>   3608172</td><td>  192.7</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>519165688</td><td>3961.0</td><td>7175451455</td><td>54744.4</td><td>6302975712</td><td>48087.9</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &   2022680 &  108.1 &    3608172 &   192.7 &    3608172 &   192.7\\\\\n",
       "\tVcells & 519165688 & 3961.0 & 7175451455 & 54744.4 & 6302975712 & 48087.9\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |   2022680 |  108.1 |    3608172 |   192.7 |    3608172 |   192.7 |\n",
       "| Vcells | 519165688 | 3961.0 | 7175451455 | 54744.4 | 6302975712 | 48087.9 |\n",
       "\n"
      ],
      "text/plain": [
       "       used      (Mb)   gc trigger (Mb)    max used   (Mb)   \n",
       "Ncells   2022680  108.1    3608172   192.7    3608172   192.7\n",
       "Vcells 519165688 3961.0 7175451455 54744.4 6302975712 48087.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "Sys.time()\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "source(\"/home/vickydiliscia/dmeyf2025/src/churn/C2003/config-APO2003-C202106.r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "source(PARAM$utils$promedios)\n",
    "source(PARAM$utils$ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sourcing: add_divisiones.R\n",
      "\n",
      "Sourcing: add_ratio.R\n",
      "\n",
      "Sourcing: agregar_clase_ternaria.R\n",
      "\n",
      "Sourcing: crear_proporcion.R\n",
      "\n",
      "Sourcing: interpolar_faltantes.R\n",
      "\n",
      "Sourcing: suma_segura.R\n",
      "\n",
      "Sourcing: ver_meses_rotos.R\n",
      "\n",
      "✅ Todas las funciones fueron cargadas correctamente.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source(file.path(PARAM$paths$functions, \"index.R\"))\n",
    "source_functions(PARAM$paths$functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento_folder <- PARAM$experimento\n",
    "dir.create(experimento_folder, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dseB4qb9RqUb"
   },
   "source": [
    "### Generacion de la clase_ternaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "P863YZB9R1Ua"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-12 16:59:10 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sys.time()\n",
    "require( \"data.table\" )\n",
    "# leo el dataset\n",
    "dataset <- fread(PARAM$paths$datasetcrudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset <- agregar_clase_ternaria(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 93 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>foto_mes</th><th scope=col>clase_ternaria</th><th scope=col>N</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>201901</td><td>BAJA+1  </td><td>   645</td></tr>\n",
       "\t<tr><td>201901</td><td>BAJA+2  </td><td>   729</td></tr>\n",
       "\t<tr><td>201901</td><td>CONTINUA</td><td>122899</td></tr>\n",
       "\t<tr><td>201902</td><td>BAJA+1  </td><td>   733</td></tr>\n",
       "\t<tr><td>201902</td><td>BAJA+2  </td><td>   707</td></tr>\n",
       "\t<tr><td>201902</td><td>CONTINUA</td><td>123961</td></tr>\n",
       "\t<tr><td>201903</td><td>BAJA+1  </td><td>   708</td></tr>\n",
       "\t<tr><td>201903</td><td>BAJA+2  </td><td>   751</td></tr>\n",
       "\t<tr><td>201903</td><td>CONTINUA</td><td>124508</td></tr>\n",
       "\t<tr><td>201904</td><td>BAJA+1  </td><td>   756</td></tr>\n",
       "\t<tr><td>201904</td><td>BAJA+2  </td><td>   514</td></tr>\n",
       "\t<tr><td>201904</td><td>CONTINUA</td><td>125268</td></tr>\n",
       "\t<tr><td>201905</td><td>BAJA+1  </td><td>   517</td></tr>\n",
       "\t<tr><td>201905</td><td>BAJA+2  </td><td>   692</td></tr>\n",
       "\t<tr><td>201905</td><td>CONTINUA</td><td>125993</td></tr>\n",
       "\t<tr><td>201906</td><td>BAJA+1  </td><td>   696</td></tr>\n",
       "\t<tr><td>201906</td><td>BAJA+2  </td><td>   608</td></tr>\n",
       "\t<tr><td>201906</td><td>CONTINUA</td><td>127430</td></tr>\n",
       "\t<tr><td>201907</td><td>BAJA+1  </td><td>   611</td></tr>\n",
       "\t<tr><td>201907</td><td>BAJA+2  </td><td>   680</td></tr>\n",
       "\t<tr><td>201907</td><td>CONTINUA</td><td>128977</td></tr>\n",
       "\t<tr><td>201908</td><td>BAJA+1  </td><td>   683</td></tr>\n",
       "\t<tr><td>201908</td><td>BAJA+2  </td><td>   577</td></tr>\n",
       "\t<tr><td>201908</td><td>CONTINUA</td><td>130883</td></tr>\n",
       "\t<tr><td>201909</td><td>BAJA+1  </td><td>   581</td></tr>\n",
       "\t<tr><td>201909</td><td>BAJA+2  </td><td>   582</td></tr>\n",
       "\t<tr><td>201909</td><td>CONTINUA</td><td>132594</td></tr>\n",
       "\t<tr><td>201910</td><td>BAJA+1  </td><td>   594</td></tr>\n",
       "\t<tr><td>201910</td><td>BAJA+2  </td><td>   618</td></tr>\n",
       "\t<tr><td>201910</td><td>CONTINUA</td><td>134798</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>202010</td><td>BAJA+1  </td><td>   544</td></tr>\n",
       "\t<tr><td>202010</td><td>BAJA+2  </td><td>   454</td></tr>\n",
       "\t<tr><td>202010</td><td>CONTINUA</td><td>158171</td></tr>\n",
       "\t<tr><td>202011</td><td>BAJA+1  </td><td>   456</td></tr>\n",
       "\t<tr><td>202011</td><td>BAJA+2  </td><td>   616</td></tr>\n",
       "\t<tr><td>202011</td><td>CONTINUA</td><td>159178</td></tr>\n",
       "\t<tr><td>202012</td><td>BAJA+1  </td><td>   622</td></tr>\n",
       "\t<tr><td>202012</td><td>BAJA+2  </td><td>   619</td></tr>\n",
       "\t<tr><td>202012</td><td>CONTINUA</td><td>159756</td></tr>\n",
       "\t<tr><td>202101</td><td>BAJA+1  </td><td>   622</td></tr>\n",
       "\t<tr><td>202101</td><td>BAJA+2  </td><td>   825</td></tr>\n",
       "\t<tr><td>202101</td><td>CONTINUA</td><td>160080</td></tr>\n",
       "\t<tr><td>202102</td><td>BAJA+1  </td><td>   831</td></tr>\n",
       "\t<tr><td>202102</td><td>BAJA+2  </td><td>  1032</td></tr>\n",
       "\t<tr><td>202102</td><td>CONTINUA</td><td>160292</td></tr>\n",
       "\t<tr><td>202103</td><td>BAJA+1  </td><td>  1039</td></tr>\n",
       "\t<tr><td>202103</td><td>BAJA+2  </td><td>   951</td></tr>\n",
       "\t<tr><td>202103</td><td>CONTINUA</td><td>161119</td></tr>\n",
       "\t<tr><td>202104</td><td>BAJA+1  </td><td>   955</td></tr>\n",
       "\t<tr><td>202104</td><td>BAJA+2  </td><td>  1130</td></tr>\n",
       "\t<tr><td>202104</td><td>CONTINUA</td><td>161333</td></tr>\n",
       "\t<tr><td>202105</td><td>BAJA+1  </td><td>  1134</td></tr>\n",
       "\t<tr><td>202105</td><td>BAJA+2  </td><td>   842</td></tr>\n",
       "\t<tr><td>202105</td><td>CONTINUA</td><td>161941</td></tr>\n",
       "\t<tr><td>202106</td><td>BAJA+1  </td><td>   843</td></tr>\n",
       "\t<tr><td>202106</td><td>BAJA+2  </td><td>  1134</td></tr>\n",
       "\t<tr><td>202106</td><td>CONTINUA</td><td>162336</td></tr>\n",
       "\t<tr><td>202107</td><td>NA      </td><td>163459</td></tr>\n",
       "\t<tr><td>202107</td><td>BAJA+1  </td><td>  1137</td></tr>\n",
       "\t<tr><td>202108</td><td>NA      </td><td>164822</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 93 × 3\n",
       "\\begin{tabular}{lll}\n",
       " foto\\_mes & clase\\_ternaria & N\\\\\n",
       " <int> & <chr> & <int>\\\\\n",
       "\\hline\n",
       "\t 201901 & BAJA+1   &    645\\\\\n",
       "\t 201901 & BAJA+2   &    729\\\\\n",
       "\t 201901 & CONTINUA & 122899\\\\\n",
       "\t 201902 & BAJA+1   &    733\\\\\n",
       "\t 201902 & BAJA+2   &    707\\\\\n",
       "\t 201902 & CONTINUA & 123961\\\\\n",
       "\t 201903 & BAJA+1   &    708\\\\\n",
       "\t 201903 & BAJA+2   &    751\\\\\n",
       "\t 201903 & CONTINUA & 124508\\\\\n",
       "\t 201904 & BAJA+1   &    756\\\\\n",
       "\t 201904 & BAJA+2   &    514\\\\\n",
       "\t 201904 & CONTINUA & 125268\\\\\n",
       "\t 201905 & BAJA+1   &    517\\\\\n",
       "\t 201905 & BAJA+2   &    692\\\\\n",
       "\t 201905 & CONTINUA & 125993\\\\\n",
       "\t 201906 & BAJA+1   &    696\\\\\n",
       "\t 201906 & BAJA+2   &    608\\\\\n",
       "\t 201906 & CONTINUA & 127430\\\\\n",
       "\t 201907 & BAJA+1   &    611\\\\\n",
       "\t 201907 & BAJA+2   &    680\\\\\n",
       "\t 201907 & CONTINUA & 128977\\\\\n",
       "\t 201908 & BAJA+1   &    683\\\\\n",
       "\t 201908 & BAJA+2   &    577\\\\\n",
       "\t 201908 & CONTINUA & 130883\\\\\n",
       "\t 201909 & BAJA+1   &    581\\\\\n",
       "\t 201909 & BAJA+2   &    582\\\\\n",
       "\t 201909 & CONTINUA & 132594\\\\\n",
       "\t 201910 & BAJA+1   &    594\\\\\n",
       "\t 201910 & BAJA+2   &    618\\\\\n",
       "\t 201910 & CONTINUA & 134798\\\\\n",
       "\t ⋮ & ⋮ & ⋮\\\\\n",
       "\t 202010 & BAJA+1   &    544\\\\\n",
       "\t 202010 & BAJA+2   &    454\\\\\n",
       "\t 202010 & CONTINUA & 158171\\\\\n",
       "\t 202011 & BAJA+1   &    456\\\\\n",
       "\t 202011 & BAJA+2   &    616\\\\\n",
       "\t 202011 & CONTINUA & 159178\\\\\n",
       "\t 202012 & BAJA+1   &    622\\\\\n",
       "\t 202012 & BAJA+2   &    619\\\\\n",
       "\t 202012 & CONTINUA & 159756\\\\\n",
       "\t 202101 & BAJA+1   &    622\\\\\n",
       "\t 202101 & BAJA+2   &    825\\\\\n",
       "\t 202101 & CONTINUA & 160080\\\\\n",
       "\t 202102 & BAJA+1   &    831\\\\\n",
       "\t 202102 & BAJA+2   &   1032\\\\\n",
       "\t 202102 & CONTINUA & 160292\\\\\n",
       "\t 202103 & BAJA+1   &   1039\\\\\n",
       "\t 202103 & BAJA+2   &    951\\\\\n",
       "\t 202103 & CONTINUA & 161119\\\\\n",
       "\t 202104 & BAJA+1   &    955\\\\\n",
       "\t 202104 & BAJA+2   &   1130\\\\\n",
       "\t 202104 & CONTINUA & 161333\\\\\n",
       "\t 202105 & BAJA+1   &   1134\\\\\n",
       "\t 202105 & BAJA+2   &    842\\\\\n",
       "\t 202105 & CONTINUA & 161941\\\\\n",
       "\t 202106 & BAJA+1   &    843\\\\\n",
       "\t 202106 & BAJA+2   &   1134\\\\\n",
       "\t 202106 & CONTINUA & 162336\\\\\n",
       "\t 202107 & NA       & 163459\\\\\n",
       "\t 202107 & BAJA+1   &   1137\\\\\n",
       "\t 202108 & NA       & 164822\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 93 × 3\n",
       "\n",
       "| foto_mes &lt;int&gt; | clase_ternaria &lt;chr&gt; | N &lt;int&gt; |\n",
       "|---|---|---|\n",
       "| 201901 | BAJA+1   |    645 |\n",
       "| 201901 | BAJA+2   |    729 |\n",
       "| 201901 | CONTINUA | 122899 |\n",
       "| 201902 | BAJA+1   |    733 |\n",
       "| 201902 | BAJA+2   |    707 |\n",
       "| 201902 | CONTINUA | 123961 |\n",
       "| 201903 | BAJA+1   |    708 |\n",
       "| 201903 | BAJA+2   |    751 |\n",
       "| 201903 | CONTINUA | 124508 |\n",
       "| 201904 | BAJA+1   |    756 |\n",
       "| 201904 | BAJA+2   |    514 |\n",
       "| 201904 | CONTINUA | 125268 |\n",
       "| 201905 | BAJA+1   |    517 |\n",
       "| 201905 | BAJA+2   |    692 |\n",
       "| 201905 | CONTINUA | 125993 |\n",
       "| 201906 | BAJA+1   |    696 |\n",
       "| 201906 | BAJA+2   |    608 |\n",
       "| 201906 | CONTINUA | 127430 |\n",
       "| 201907 | BAJA+1   |    611 |\n",
       "| 201907 | BAJA+2   |    680 |\n",
       "| 201907 | CONTINUA | 128977 |\n",
       "| 201908 | BAJA+1   |    683 |\n",
       "| 201908 | BAJA+2   |    577 |\n",
       "| 201908 | CONTINUA | 130883 |\n",
       "| 201909 | BAJA+1   |    581 |\n",
       "| 201909 | BAJA+2   |    582 |\n",
       "| 201909 | CONTINUA | 132594 |\n",
       "| 201910 | BAJA+1   |    594 |\n",
       "| 201910 | BAJA+2   |    618 |\n",
       "| 201910 | CONTINUA | 134798 |\n",
       "| ⋮ | ⋮ | ⋮ |\n",
       "| 202010 | BAJA+1   |    544 |\n",
       "| 202010 | BAJA+2   |    454 |\n",
       "| 202010 | CONTINUA | 158171 |\n",
       "| 202011 | BAJA+1   |    456 |\n",
       "| 202011 | BAJA+2   |    616 |\n",
       "| 202011 | CONTINUA | 159178 |\n",
       "| 202012 | BAJA+1   |    622 |\n",
       "| 202012 | BAJA+2   |    619 |\n",
       "| 202012 | CONTINUA | 159756 |\n",
       "| 202101 | BAJA+1   |    622 |\n",
       "| 202101 | BAJA+2   |    825 |\n",
       "| 202101 | CONTINUA | 160080 |\n",
       "| 202102 | BAJA+1   |    831 |\n",
       "| 202102 | BAJA+2   |   1032 |\n",
       "| 202102 | CONTINUA | 160292 |\n",
       "| 202103 | BAJA+1   |   1039 |\n",
       "| 202103 | BAJA+2   |    951 |\n",
       "| 202103 | CONTINUA | 161119 |\n",
       "| 202104 | BAJA+1   |    955 |\n",
       "| 202104 | BAJA+2   |   1130 |\n",
       "| 202104 | CONTINUA | 161333 |\n",
       "| 202105 | BAJA+1   |   1134 |\n",
       "| 202105 | BAJA+2   |    842 |\n",
       "| 202105 | CONTINUA | 161941 |\n",
       "| 202106 | BAJA+1   |    843 |\n",
       "| 202106 | BAJA+2   |   1134 |\n",
       "| 202106 | CONTINUA | 162336 |\n",
       "| 202107 | NA       | 163459 |\n",
       "| 202107 | BAJA+1   |   1137 |\n",
       "| 202108 | NA       | 164822 |\n",
       "\n"
      ],
      "text/plain": [
       "   foto_mes clase_ternaria N     \n",
       "1  201901   BAJA+1            645\n",
       "2  201901   BAJA+2            729\n",
       "3  201901   CONTINUA       122899\n",
       "4  201902   BAJA+1            733\n",
       "5  201902   BAJA+2            707\n",
       "6  201902   CONTINUA       123961\n",
       "7  201903   BAJA+1            708\n",
       "8  201903   BAJA+2            751\n",
       "9  201903   CONTINUA       124508\n",
       "10 201904   BAJA+1            756\n",
       "11 201904   BAJA+2            514\n",
       "12 201904   CONTINUA       125268\n",
       "13 201905   BAJA+1            517\n",
       "14 201905   BAJA+2            692\n",
       "15 201905   CONTINUA       125993\n",
       "16 201906   BAJA+1            696\n",
       "17 201906   BAJA+2            608\n",
       "18 201906   CONTINUA       127430\n",
       "19 201907   BAJA+1            611\n",
       "20 201907   BAJA+2            680\n",
       "21 201907   CONTINUA       128977\n",
       "22 201908   BAJA+1            683\n",
       "23 201908   BAJA+2            577\n",
       "24 201908   CONTINUA       130883\n",
       "25 201909   BAJA+1            581\n",
       "26 201909   BAJA+2            582\n",
       "27 201909   CONTINUA       132594\n",
       "28 201910   BAJA+1            594\n",
       "29 201910   BAJA+2            618\n",
       "30 201910   CONTINUA       134798\n",
       "⋮  ⋮        ⋮              ⋮     \n",
       "64 202010   BAJA+1            544\n",
       "65 202010   BAJA+2            454\n",
       "66 202010   CONTINUA       158171\n",
       "67 202011   BAJA+1            456\n",
       "68 202011   BAJA+2            616\n",
       "69 202011   CONTINUA       159178\n",
       "70 202012   BAJA+1            622\n",
       "71 202012   BAJA+2            619\n",
       "72 202012   CONTINUA       159756\n",
       "73 202101   BAJA+1            622\n",
       "74 202101   BAJA+2            825\n",
       "75 202101   CONTINUA       160080\n",
       "76 202102   BAJA+1            831\n",
       "77 202102   BAJA+2           1032\n",
       "78 202102   CONTINUA       160292\n",
       "79 202103   BAJA+1           1039\n",
       "80 202103   BAJA+2            951\n",
       "81 202103   CONTINUA       161119\n",
       "82 202104   BAJA+1            955\n",
       "83 202104   BAJA+2           1130\n",
       "84 202104   CONTINUA       161333\n",
       "85 202105   BAJA+1           1134\n",
       "86 202105   BAJA+2            842\n",
       "87 202105   CONTINUA       161941\n",
       "88 202106   BAJA+1            843\n",
       "89 202106   BAJA+2           1134\n",
       "90 202106   CONTINUA       162336\n",
       "91 202107   NA             163459\n",
       "92 202107   BAJA+1           1137\n",
       "93 202108   NA             164822"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setorder( dataset, foto_mes, clase_ternaria, numero_de_cliente)\n",
    "dataset[, .N, list(foto_mes, clase_ternaria)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSKhZRToy2F7"
   },
   "source": [
    "### Eliminacion de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completar a gusto LUEGO de realizar un analisis exploratorio de datos.\n",
    "<br> No necesariamente en esta Segunda Competencia conviele eliminar los mismos campos que en la Primera ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salsa Magica para 202106\n",
    "dataset[, mprestamos_personales := NULL ]\n",
    "dataset[, cprestamos_personales := NULL ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Drifting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe corregir el drifting natural que ocurre en loa datos, en particular los datos monetarios que se vieron fuertemente afectados por una alta inflación\n",
    "<br> Posibles métodos son:\n",
    "* No hacer absolutamente nada\n",
    "* Ajuste de valores monetarios por indices del tipo :\n",
    "   * IPC  Indice de Precios al Consumidor\n",
    "   * Dolar Oficial\n",
    "   * Dolar Blue\n",
    "   * UVA  Unidad de Valor Adquisitivo\n",
    "\n",
    "a este codigo de Data Drifting lo debera escribir usted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Intra-Mes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear variables nuevas a partir de las existentes dentro del mismo registro, **sin** ir a buscar información histórica.\n",
    "<br> El siguiente código es un mínimo ejemplo, agregar nuevos features a gusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# el mes 1,2, ..12 , podria servir para detectar estacionalidad\n",
    "dataset[, kmes := foto_mes %% 100]\n",
    "\n",
    "# creo un ctr_quarter que tenga en cuenta cuando\n",
    "# los clientes hace 3 menos meses que estan\n",
    "# ya que seria injusto considerar las transacciones medidas en menor tiempo\n",
    "dataset[, ctrx_quarter_normalizado := as.numeric(ctrx_quarter) ]\n",
    "dataset[cliente_antiguedad == 1, ctrx_quarter_normalizado := ctrx_quarter * 5.0]\n",
    "dataset[cliente_antiguedad == 2, ctrx_quarter_normalizado := ctrx_quarter * 2.0]\n",
    "dataset[cliente_antiguedad == 3, ctrx_quarter_normalizado := ctrx_quarter * 1.2]\n",
    "\n",
    "# variable extraida de una tesis de maestria de Irlanda, se perdió el link\n",
    "dataset[, mpayroll_sobre_edad := mpayroll / cliente_edad]\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Historico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if( !require(\"Rcpp\")) install.packages(\"Rcpp\", repos = \"http://cran.us.r-project.org\")\n",
    "require(\"Rcpp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se calculan para los 6 meses previos el minimo, maximo y\n",
    "#  tendencia calculada con cuadrados minimos\n",
    "# la formula de calculo de la tendencia puede verse en\n",
    "#  https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Introductory_Statistics_(Shafer_and_Zhang)/10%3A_Correlation_and_Regression/10.04%3A_The_Least_Squares_Regression_Line\n",
    "# para la maxíma velocidad esta funcion esta escrita en lenguaje C,\n",
    "# y no en la porqueria de R o Python\n",
    "\n",
    "cppFunction(\"NumericVector fhistC(NumericVector pcolumna, IntegerVector pdesde )\n",
    "{\n",
    "  /* Aqui se cargan los valores para la regresion */\n",
    "  double  x[100] ;\n",
    "  double  y[100] ;\n",
    "\n",
    "  int n = pcolumna.size();\n",
    "  NumericVector out( 5*n );\n",
    "\n",
    "  for(int i = 0; i < n; i++)\n",
    "  {\n",
    "    //lag\n",
    "    if( pdesde[i]-1 < i )  out[ i + 4*n ]  =  pcolumna[i-1] ;\n",
    "    else                   out[ i + 4*n ]  =  NA_REAL ;\n",
    "\n",
    "\n",
    "    int  libre    = 0 ;\n",
    "    int  xvalor   = 1 ;\n",
    "\n",
    "    for( int j= pdesde[i]-1;  j<=i; j++ )\n",
    "    {\n",
    "       double a = pcolumna[j] ;\n",
    "\n",
    "       if( !R_IsNA( a ) )\n",
    "       {\n",
    "          y[ libre ]= a ;\n",
    "          x[ libre ]= xvalor ;\n",
    "          libre++ ;\n",
    "       }\n",
    "\n",
    "       xvalor++ ;\n",
    "    }\n",
    "\n",
    "    /* Si hay al menos dos valores */\n",
    "    if( libre > 1 )\n",
    "    {\n",
    "      double  xsum  = x[0] ;\n",
    "      double  ysum  = y[0] ;\n",
    "      double  xysum = xsum * ysum ;\n",
    "      double  xxsum = xsum * xsum ;\n",
    "      double  vmin  = y[0] ;\n",
    "      double  vmax  = y[0] ;\n",
    "\n",
    "      for( int h=1; h<libre; h++)\n",
    "      {\n",
    "        xsum  += x[h] ;\n",
    "        ysum  += y[h] ;\n",
    "        xysum += x[h]*y[h] ;\n",
    "        xxsum += x[h]*x[h] ;\n",
    "\n",
    "        if( y[h] < vmin )  vmin = y[h] ;\n",
    "        if( y[h] > vmax )  vmax = y[h] ;\n",
    "      }\n",
    "\n",
    "      out[ i ]  =  (libre*xysum - xsum*ysum)/(libre*xxsum -xsum*xsum) ;\n",
    "      out[ i + n ]    =  vmin ;\n",
    "      out[ i + 2*n ]  =  vmax ;\n",
    "      out[ i + 3*n ]  =  ysum / libre ;\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "      out[ i       ]  =  NA_REAL ;\n",
    "      out[ i + n   ]  =  NA_REAL ;\n",
    "      out[ i + 2*n ]  =  NA_REAL ;\n",
    "      out[ i + 3*n ]  =  NA_REAL ;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return  out;\n",
    "}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcula la tendencia de las variables cols de los ultimos 6 meses\n",
    "# la tendencia es la pendiente de la recta que ajusta por cuadrados minimos\n",
    "# La funcionalidad de ratioavg es autoria de  Daiana Sparta,  UAustral  2021\n",
    "\n",
    "TendenciaYmuchomas <- function(\n",
    "    dataset, cols, ventana = 6, tendencia = TRUE,\n",
    "    minimo = TRUE, maximo = TRUE, promedio = TRUE,\n",
    "    ratioavg = FALSE, ratiomax = FALSE) {\n",
    "  gc(verbose= FALSE)\n",
    "  # Esta es la cantidad de meses que utilizo para la historia\n",
    "  ventana_regresion <- ventana\n",
    "\n",
    "  last <- nrow(dataset)\n",
    "\n",
    "  # creo el vector_desde que indica cada ventana\n",
    "  # de esta forma se acelera el procesamiento ya que lo hago una sola vez\n",
    "  vector_ids <- dataset[ , numero_de_cliente ]\n",
    "\n",
    "  vector_desde <- seq(\n",
    "    -ventana_regresion + 2,\n",
    "    nrow(dataset) - ventana_regresion + 1\n",
    "  )\n",
    "\n",
    "  vector_desde[1:ventana_regresion] <- 1\n",
    "\n",
    "  for (i in 2:last) {\n",
    "    if (vector_ids[i - 1] != vector_ids[i]) {\n",
    "      vector_desde[i] <- i\n",
    "    }\n",
    "  }\n",
    "  for (i in 2:last) {\n",
    "    if (vector_desde[i] < vector_desde[i - 1]) {\n",
    "      vector_desde[i] <- vector_desde[i - 1]\n",
    "    }\n",
    "  }\n",
    "\n",
    "  for (campo in cols) {\n",
    "    nueva_col <- fhistC(dataset[, get(campo)], vector_desde)\n",
    "\n",
    "    if (tendencia) {\n",
    "      dataset[, paste0(campo, \"_tend\", ventana) :=\n",
    "        nueva_col[(0 * last + 1):(1 * last)]]\n",
    "    }\n",
    "\n",
    "    if (minimo) {\n",
    "      dataset[, paste0(campo, \"_min\", ventana) :=\n",
    "        nueva_col[(1 * last + 1):(2 * last)]]\n",
    "    }\n",
    "\n",
    "    if (maximo) {\n",
    "      dataset[, paste0(campo, \"_max\", ventana) :=\n",
    "        nueva_col[(2 * last + 1):(3 * last)]]\n",
    "    }\n",
    "\n",
    "    if (promedio) {\n",
    "      dataset[, paste0(campo, \"_avg\", ventana) :=\n",
    "        nueva_col[(3 * last + 1):(4 * last)]]\n",
    "    }\n",
    "\n",
    "    if (ratioavg) {\n",
    "      dataset[, paste0(campo, \"_ratioavg\", ventana) :=\n",
    "        get(campo) / nueva_col[(3 * last + 1):(4 * last)]]\n",
    "    }\n",
    "\n",
    "    if (ratiomax) {\n",
    "      dataset[, paste0(campo, \"_ratiomax\", ventana) :=\n",
    "        get(campo) / nueva_col[(2 * last + 1):(3 * last)]]\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Historico\n",
    "# Creacion de LAGs\n",
    "setorder(dataset, numero_de_cliente, foto_mes)\n",
    "\n",
    "# todo es lagueable, menos la primary key y la clase\n",
    "cols_lagueables <- copy( setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\")\n",
    "))\n",
    "\n",
    "# https://rdrr.io/cran/data.table/man/shift.html\n",
    "\n",
    "# lags de orden 1\n",
    "dataset[,\n",
    "  paste0(cols_lagueables, \"_lag1\") := shift(.SD, 1, NA, \"lag\"),\n",
    "  by= numero_de_cliente,\n",
    "  .SDcols= cols_lagueables\n",
    "]\n",
    "\n",
    "# lags de orden 2\n",
    "dataset[,\n",
    "  paste0(cols_lagueables, \"_lag2\") := shift(.SD, 2, NA, \"lag\"),\n",
    "  by= numero_de_cliente,\n",
    "  .SDcols= cols_lagueables\n",
    "]\n",
    "\n",
    "# agrego los delta lags\n",
    "for (vcol in cols_lagueables)\n",
    "{\n",
    "  dataset[, paste0(vcol, \"_delta1\") := get(vcol) - get(paste0(vcol, \"_lag1\"))]\n",
    "  dataset[, paste0(vcol, \"_delta2\") := get(vcol) - get(paste0(vcol, \"_lag2\"))]\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros de Feature Engineering Historico de Tendencias\n",
    "PARAM$FE_hist$Tendencias$run <- TRUE\n",
    "PARAM$FE_hist$Tendencias$ventana <- 6\n",
    "PARAM$FE_hist$Tendencias$tendencia <- TRUE\n",
    "PARAM$FE_hist$Tendencias$minimo <- FALSE\n",
    "PARAM$FE_hist$Tendencias$maximo <- FALSE\n",
    "PARAM$FE_hist$Tendencias$promedio <- FALSE\n",
    "PARAM$FE_hist$Tendencias$ratioavg <- FALSE\n",
    "PARAM$FE_hist$Tendencias$ratiomax <- FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aqui se agregan las tendencias de los ultimos 6 meses\n",
    "\n",
    "cols_lagueables <- intersect(cols_lagueables, colnames(dataset))\n",
    "setorder(dataset, numero_de_cliente, foto_mes)\n",
    "\n",
    "if( PARAM$FE_hist$Tendencias$run) {\n",
    "    TendenciaYmuchomas(dataset,\n",
    "    cols = cols_lagueables,\n",
    "    ventana = PARAM$FE_hist$Tendencias$ventana, # 6 meses de historia\n",
    "    tendencia = PARAM$FE_hist$Tendencias$tendencia,\n",
    "    minimo = PARAM$FE_hist$Tendencias$minimo,\n",
    "    maximo = PARAM$FE_hist$Tendencias$maximo,\n",
    "    promedio = PARAM$FE_hist$Tendencias$promedio,\n",
    "    ratioavg = PARAM$FE_hist$Tendencias$ratioavg,\n",
    "    ratiomax = PARAM$FE_hist$Tendencias$ratiomax\n",
    "  )\n",
    "}\n",
    "\n",
    "ncol(dataset)\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering a partir de hojas de Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if( !require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AgregaVarRandomForest <- function() {\n",
    "\n",
    "  cat( \"inicio AgregaVarRandomForest()\\n\")\n",
    "  gc(verbose= FALSE)\n",
    "  dataset[, clase01 := 0L ]\n",
    "  dataset[ clase_ternaria %in% c( \"BAJA+2\", \"BAJA+1\"),\n",
    "      clase01 := 1L ]\n",
    "\n",
    "  campos_buenos <- setdiff(\n",
    "    colnames(dataset),\n",
    "    c( \"clase_ternaria\", \"clase01\")\n",
    "  )\n",
    "\n",
    "  dataset[, entrenamiento :=\n",
    "    as.integer( foto_mes %in% PARAM$FE_rf$train$training )]\n",
    "\n",
    "  dtrain <- lgb.Dataset(\n",
    "    data = data.matrix(dataset[entrenamiento == TRUE, campos_buenos, with = FALSE]),\n",
    "    label = dataset[entrenamiento == TRUE, clase01],\n",
    "    free_raw_data = FALSE\n",
    "  )\n",
    "\n",
    "  modelo <- lgb.train(\n",
    "     data = dtrain,\n",
    "     param = PARAM$FE_rf$lgb_param,\n",
    "     verbose = -100\n",
    "  )\n",
    "\n",
    "  cat( \"Fin construccion RandomForest\\n\" )\n",
    "  # grabo el modelo, achivo .model\n",
    "  lgb.save(modelo, file=\"modelo.model\" )\n",
    "\n",
    "  qarbolitos <- copy(PARAM$FE_rf$lgb_param$num_iterations)\n",
    "\n",
    "  periodos <- dataset[ , unique( foto_mes ) ]\n",
    "\n",
    "  for( periodo in  periodos )\n",
    "  {\n",
    "    cat( \"periodo = \", periodo, \"\\n\" )\n",
    "    datamatrix <- data.matrix(dataset[ foto_mes== periodo, campos_buenos, with = FALSE])\n",
    "\n",
    "    cat( \"Inicio prediccion\\n\" )\n",
    "    prediccion <- predict(\n",
    "        modelo,\n",
    "        datamatrix,\n",
    "        type = \"leaf\"\n",
    "    )\n",
    "    cat( \"Fin prediccion\\n\" )\n",
    "\n",
    "    for( arbolito in 1:qarbolitos )\n",
    "    {\n",
    "       cat( arbolito, \" \" )\n",
    "       hojas_arbol <- unique(prediccion[ , arbolito])\n",
    "\n",
    "       for (pos in 1:length(hojas_arbol)) {\n",
    "         # el numero de nodo de la hoja, estan salteados\n",
    "         nodo_id <- hojas_arbol[pos]\n",
    "         dataset[ foto_mes== periodo, paste0(\n",
    "            \"rf_\", sprintf(\"%03d\", arbolito),\n",
    "             \"_\", sprintf(\"%03d\", nodo_id)\n",
    "          ) :=  as.integer( nodo_id == prediccion[ , arbolito]) ]\n",
    "\n",
    "       }\n",
    "\n",
    "       rm( hojas_arbol )\n",
    "    }\n",
    "    cat( \"\\n\" )\n",
    "\n",
    "    rm( prediccion )\n",
    "    rm( datamatrix )\n",
    "    gc(verbose= FALSE)\n",
    "  }\n",
    "\n",
    "  gc(verbose= FALSE)\n",
    "\n",
    "  # borro clase01 , no debe ensuciar el dataset\n",
    "  dataset[ , clase01 := NULL ]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros de Feature Engineering  a partir de hojas de Random Forest\n",
    "\n",
    "# Estos CUATRO parametros son los que se deben modificar\n",
    "PARAM$FE_rf$arbolitos= 20\n",
    "PARAM$FE_rf$hojas_por_arbol= 16\n",
    "PARAM$FE_rf$datos_por_hoja= 100\n",
    "PARAM$FE_rf$mtry_ratio= 0.2\n",
    "\n",
    "# Estos son quasi fijos\n",
    "PARAM$FE_rf$train$training <- c( 202101, 202102, 202103)\n",
    "\n",
    "# Estos TAMBIEN son quasi fijos\n",
    "PARAM$FE_rf$lgb_param <-list(\n",
    "    # parametros que se pueden cambiar\n",
    "    num_iterations = PARAM$FE_rf$arbolitos,\n",
    "    num_leaves  = PARAM$FE_rf$hojas_por_arbol,\n",
    "    min_data_in_leaf = PARAM$FE_rf$datos_por_hoja,\n",
    "    feature_fraction_bynode  = PARAM$FE_rf$mtry_ratio,\n",
    "\n",
    "    # para que LightGBM emule Random Forest\n",
    "    boosting = \"rf\",\n",
    "    bagging_fraction = ( 1.0 - 1.0/exp(1.0) ),\n",
    "    bagging_freq = 1.0,\n",
    "    feature_fraction = 1.0,\n",
    "\n",
    "    # genericos de LightGBM\n",
    "    max_bin = 31L,\n",
    "    objective = \"binary\",\n",
    "    first_metric_only = TRUE,\n",
    "    boost_from_average = TRUE,\n",
    "    feature_pre_filter = FALSE,\n",
    "    force_row_wise = TRUE,\n",
    "    verbosity = -100,\n",
    "    max_depth = -1L,\n",
    "    min_gain_to_split = 0.0,\n",
    "    min_sum_hessian_in_leaf = 0.001,\n",
    "    lambda_l1 = 0.0,\n",
    "    lambda_l2 = 0.0,\n",
    "\n",
    "    pos_bagging_fraction = 1.0,\n",
    "    neg_bagging_fraction = 1.0,\n",
    "    is_unbalance = FALSE,\n",
    "    scale_pos_weight = 1.0,\n",
    "\n",
    "    drop_rate = 0.1,\n",
    "    max_drop = 50,\n",
    "    skip_drop = 0.5,\n",
    "\n",
    "    extra_trees = FALSE\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering agregando variables de Random Forest\n",
    "#  aqui es donde se hace el trabajo\n",
    "AgregaVarRandomForest()\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol(dataset)\n",
    "colnames(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizacion de Hipeparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hacemos optimizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp4-Bj3aYI8d"
   },
   "source": [
    "## Produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las decisiones que se toman para la construccion del modelo final son:\n",
    "* Los positvos son  POS={\"BAJA+1\", \"BAJA+2\"}, esta es una meticulosa decisión.\n",
    "* Se entrena en todos los meses salvo los de pandemia esta es una meticulosa decisión.\n",
    "* Se hace un muy consevador undersampling del **0.50** = 50% de la clase mayoritaria (los \"CONTINUA\" )\n",
    "* Obviamente los datos donde se aplica el modelo es el mes  {202106}\n",
    "* Por experimentos en meses anteriores, se decide cortar en los 11000 registros con mayor probabildiad de POS={\"BAJA+1\", \"BAJA+2\"}, , esta es una *enorme* decisión.\n",
    "* No se optmizan los hiperparámetros de LightGBM, sino que se llama a la libreria *zLightGBM*\n",
    "* Para *zLightGBM*  se crean **100** canaritos, esta es una decisión enorme !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM$train_final$future <- c(202106)\n",
    "\n",
    "PARAM$train_final$meses <- c(\n",
    "  201901, 201902, 201903, 201904, 201905, 201906,\n",
    "  201907, 201908, 201909, 201910, 201911, 201912,\n",
    "  202001, 202002, 202003,\n",
    "  202007, 202008, 202009, 202010, 202011, 202012,\n",
    "  202101, 202102, 202103, 202104\n",
    ")\n",
    "\n",
    "PARAM$train_final$undersampling <- 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se filtran los meses donde se entrena el modelo final\n",
    "dataset_train_final <- dataset[foto_mes %in% PARAM$train_final$meses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling, van todos los \"BAJA+1\" y \"BAJA+2\" y solo algunos \"CONTINIA\"\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset_train_final[, azar := runif(nrow(dataset_train_final))]\n",
    "dataset_train_final[, training := 0L]\n",
    "\n",
    "dataset_train_final[\n",
    "  (azar <= PARAM$train_final$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]\n",
    "\n",
    "dataset_train_final[, azar:= NULL] # elimino la columna azar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "#  a partir de ahora ya NO puedo cortar  por prob(BAJA+2) > 1/40\n",
    "\n",
    "dataset_train_final[,\n",
    "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model zLGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-12 16:13:25 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# utilizo  zLightGBM  la nueva libreria\n",
    "if( !require(\"zlightgbm\") ) install.packages(\"https://storage.googleapis.com/open-courses/dmeyf2025-e4a2/zlightgbm_4.6.0.99.tar.gz\", repos= NULL, type= \"source\")\n",
    "require(\"zlightgbm\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-12 16:13:25 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols0 <- copy(colnames(dataset_train_final))\n",
    "filas <- nrow(dataset_train_final)\n",
    "\n",
    "for( i in seq(PARAM$qcanaritos) ){\n",
    "  dataset_train_final[, paste0(\"canarito_\",i) := runif( filas) ]\n",
    "}\n",
    "\n",
    "# las columnas canaritos mandatoriamente van al comienzo del dataset\n",
    "cols_canaritos <- copy( setdiff( colnames(dataset_train_final), cols0 ) )\n",
    "setcolorder( dataset_train_final, c( cols_canaritos, cols0 ) )\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# los campos que se van a utilizar\n",
    "\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset_train_final),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filas 0 columnas 1479 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-12 16:13:25 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain_final <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train_final[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train_final[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "cat(\"filas\", nrow(dtrain_final), \"columnas\", ncol(dtrain_final), \"\\n\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevos hiperparámetros en zLightGBM\n",
    "\n",
    "canaritos , entero >=0, cantidad de atributos del dataset que se consideran como canaritos, mandatoriamente en la version actual deben estar al comienzo.\n",
    "gradient_bound , numero real, >=0 cota que se pone a los scores de las hojas de los arboles, es un learning_rate adaptativo\n",
    "En el caso que canaritos==0 y gradient_bound==0 entonces xLightGBM se comporta exactamente igual a LightGBM\n",
    "\n",
    "Tener en cuenta que el hiperparámetro min_data_in_leaf se está dejando en el valor de 20 que es el default de LightGBM\n",
    "realmente valdria la pena experimentar con distintos valores de min_data_in_leaf, hay potencial de mejora !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se ejecuta zLightGBM\n",
    "no se utilizan hiperparámetros optimos para controlar el overfitting\n",
    "zLightGBM sabe cuando no hacer un split\n",
    "si al hacer el n-simo arbol, no puede hacer el split de la raiz, detiene el crecimiento del ensemble y termina\n",
    "\n",
    "claramente el min_data_in_leaf=20 que es el default de LightGBM esta jugando un papel importante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1479"
      ],
      "text/latex": [
       "1479"
      ],
      "text/markdown": [
       "1479"
      ],
      "text/plain": [
       "[1] 1479"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0</li><li>1479</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 1479\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 1479\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]    0 1479"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(dtrain_final)  # cantidad de filas (observaciones)\n",
    "ncol(dtrain_final)  # cantidad de columnas (variables)\n",
    "dim(dtrain_final)   # ambas a la vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$boosting</dt>\n",
       "\t\t<dd>'gbdt'</dd>\n",
       "\t<dt>$objective</dt>\n",
       "\t\t<dd>'binary'</dd>\n",
       "\t<dt>$metric</dt>\n",
       "\t\t<dd>'custom'</dd>\n",
       "\t<dt>$first_metric_only</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$boost_from_average</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$feature_pre_filter</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$force_row_wise</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$verbosity</dt>\n",
       "\t\t<dd>-100</dd>\n",
       "\t<dt>$seed</dt>\n",
       "\t\t<dd>100271</dd>\n",
       "\t<dt>$max_bin</dt>\n",
       "\t\t<dd>31</dd>\n",
       "\t<dt>$min_data_in_leaf</dt>\n",
       "\t\t<dd>20</dd>\n",
       "\t<dt>$num_iterations</dt>\n",
       "\t\t<dd>9999</dd>\n",
       "\t<dt>$num_leaves</dt>\n",
       "\t\t<dd>999</dd>\n",
       "\t<dt>$learning_rate</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$feature_fraction</dt>\n",
       "\t\t<dd>0.5</dd>\n",
       "\t<dt>$canaritos</dt>\n",
       "\t\t<dd>100</dd>\n",
       "\t<dt>$gradient_bound</dt>\n",
       "\t\t<dd>0.15</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$boosting] 'gbdt'\n",
       "\\item[\\$objective] 'binary'\n",
       "\\item[\\$metric] 'custom'\n",
       "\\item[\\$first\\_metric\\_only] FALSE\n",
       "\\item[\\$boost\\_from\\_average] TRUE\n",
       "\\item[\\$feature\\_pre\\_filter] FALSE\n",
       "\\item[\\$force\\_row\\_wise] TRUE\n",
       "\\item[\\$verbosity] -100\n",
       "\\item[\\$seed] 100271\n",
       "\\item[\\$max\\_bin] 31\n",
       "\\item[\\$min\\_data\\_in\\_leaf] 20\n",
       "\\item[\\$num\\_iterations] 9999\n",
       "\\item[\\$num\\_leaves] 999\n",
       "\\item[\\$learning\\_rate] 1\n",
       "\\item[\\$feature\\_fraction] 0.5\n",
       "\\item[\\$canaritos] 100\n",
       "\\item[\\$gradient\\_bound] 0.15\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$boosting\n",
       ":   'gbdt'\n",
       "$objective\n",
       ":   'binary'\n",
       "$metric\n",
       ":   'custom'\n",
       "$first_metric_only\n",
       ":   FALSE\n",
       "$boost_from_average\n",
       ":   TRUE\n",
       "$feature_pre_filter\n",
       ":   FALSE\n",
       "$force_row_wise\n",
       ":   TRUE\n",
       "$verbosity\n",
       ":   -100\n",
       "$seed\n",
       ":   100271\n",
       "$max_bin\n",
       ":   31\n",
       "$min_data_in_leaf\n",
       ":   20\n",
       "$num_iterations\n",
       ":   9999\n",
       "$num_leaves\n",
       ":   999\n",
       "$learning_rate\n",
       ":   1\n",
       "$feature_fraction\n",
       ":   0.5\n",
       "$canaritos\n",
       ":   100\n",
       "$gradient_bound\n",
       ":   0.15\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$boosting\n",
       "[1] \"gbdt\"\n",
       "\n",
       "$objective\n",
       "[1] \"binary\"\n",
       "\n",
       "$metric\n",
       "[1] \"custom\"\n",
       "\n",
       "$first_metric_only\n",
       "[1] FALSE\n",
       "\n",
       "$boost_from_average\n",
       "[1] TRUE\n",
       "\n",
       "$feature_pre_filter\n",
       "[1] FALSE\n",
       "\n",
       "$force_row_wise\n",
       "[1] TRUE\n",
       "\n",
       "$verbosity\n",
       "[1] -100\n",
       "\n",
       "$seed\n",
       "[1] 100271\n",
       "\n",
       "$max_bin\n",
       "[1] 31\n",
       "\n",
       "$min_data_in_leaf\n",
       "[1] 20\n",
       "\n",
       "$num_iterations\n",
       "[1] 9999\n",
       "\n",
       "$num_leaves\n",
       "[1] 999\n",
       "\n",
       "$learning_rate\n",
       "[1] 1\n",
       "\n",
       "$feature_fraction\n",
       "[1] 0.5\n",
       "\n",
       "$canaritos\n",
       "[1] 100\n",
       "\n",
       "$gradient_bound\n",
       "[1] 0.15\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PARAM$lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in data$construct(): Check failed: (num_data) > (0) at /tmp/Rtmpgfvcwd/R.INSTALL1ad7254b0c8c6/zlightgbm/src/src/io/dataset.cpp, line 43 .\n\n\n",
     "output_type": "error",
     "traceback": [
      "Error in data$construct(): Check failed: (num_data) > (0) at /tmp/Rtmpgfvcwd/R.INSTALL1ad7254b0c8c6/zlightgbm/src/src/io/dataset.cpp, line 43 .\n\n\nTraceback:\n",
      "1. data$construct()",
      "2. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = NULL)\n . }, \"Check failed: (num_data) > (0) at /tmp/Rtmpgfvcwd/R.INSTALL1ad7254b0c8c6/zlightgbm/src/src/io/dataset.cpp, line 43 .\\n\\n\", \n .     base::quote(data$construct()))"
     ]
    }
   ],
   "source": [
    "# entreno el modelo\n",
    "\n",
    "modelo_final <- lgb.train(\n",
    "  data= dtrain_final,\n",
    "  param= PARAM$lgbm\n",
    ")\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabo el modelo generado, esto pude ser levantado por LighGBM en cualquier maquina\n",
    "modelo_file <- paste0(PARAM$paths$models , \"/zmodelo.txt\")\n",
    "lgb.save(modelo_final, file=modelo_file)\n",
    "\n",
    "# grabo un dataset que tiene el detalle de los arboles de LightGBM\n",
    "tb_arboles <- lgb.model.dt.tree(modelo_final)\n",
    "fwrite(tb_arboles, file=\"tb_arboles.txt\", sep=\"\\t\")\n",
    "\n",
    "cat(\"cantidad arbolitos=\", tb_arboles[, max(tree_index)+1],\"\\n\" )\n",
    "cat(\"summary de las hojas de los arboles\")\n",
    "summary( tb_arboles[, list(hojas=max(leaf_index, na.rm=TRUE)+1), tree_index][,hojas])\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplico el modelo a los datos sin clase\n",
    "dfuture <- dataset[foto_mes %in% PARAM$future]\n",
    "\n",
    "# penosamente, en la versión actual de zLightGBM  los campos canaritos\n",
    "#  aunque no se utilizan para nada, también deben estar en el dataset donde se hace el predict()\n",
    "filas <- nrow(dfuture)\n",
    "\n",
    "for( i in seq(PARAM$qcanaritos) ){\n",
    "  dfuture[, paste0(\"canarito_\",i) := runif( filas) ]\n",
    "}\n",
    "\n",
    "prediccion <- predict(\n",
    "  modelo_final,\n",
    "  data.matrix(dfuture[, campos_buenos, with= FALSE]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabla de prediccion, puede ser util para futuros ensembles\n",
    "#  ya que le modelo ganador va a ser un ensemble de LightGBMs\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes)]\n",
    "tb_prediccion[, prob := prediccion ]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Se tomó la decisión de enviar a los 11000 registros con mayor probabilidad de POS={\"BAJA+1\",\"BAJA+\"}\n",
    "<br> esto se determinó en forma artesanal analizando meses anterior\n",
    "<br> esta es una muy importante decisión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir.create(\"kaggle\", showWarnings=FALSE)\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "envios <- 11000\n",
    "tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
    "tb_prediccion[1:envios, Predicted := 1L] # marco los primeros\n",
    "\n",
    "archivo_kaggle <- paste0(PARAM$paths$kaggle, PARAM$experimento, \"_\", envios, \".csv\")\n",
    "\n",
    "# grabo el archivo\n",
    "fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "  file= archivo_kaggle,\n",
    "  sep= \",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "icerca <- which.min(  abs( tb_prediccion$gan_acum - mcorte_mejor ) )\n",
    "vmodelo <- tb_prediccion[ icerca, meta_modelo ]\n",
    "tb_pred <- tb_prediccion[meta_modelo==vmodelo]\n",
    "\n",
    "icerca <- which.min(  abs( tb_pred$gan_acum - mcorte_mejor ) )\n",
    "tb_pred[, Predicted := 0L] # seteo inicial a 0\n",
    "tb_pred[1:icerca, Predicted := 1L] # marco los primeros\n",
    "\n",
    "archivo_pseudo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\",  icerca, \".csv\")\n",
    "\n",
    "# grabo el archivo\n",
    "fwrite(tb_pred[, list(numero_de_cliente, Predicted)],\n",
    "  file= archivo_pseudo_kaggle,\n",
    "  sep= \",\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Test202106"
     ]
    }
   ],
   "source": [
    "# la subida a Kaggle\n",
    "comando <- \"kaggle competitions submit\"\n",
    "competencia <- \"-c  test-202106\"\n",
    "arch <- paste( \"-f\", archivo_pseudo_kaggle)\n",
    "mensaje <-  paste0( \"-m 'exp=\", PARAM$experimento,\n",
    "  \" envios=\", icorte_mejor,\"'\")\n",
    "\n",
    "                    \n",
    "linea <- paste( comando, competencia, arch, mensaje)\n",
    "salida <- system(linea, intern=TRUE)\n",
    "cat(salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "9zA_W25c15DP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-07 21:17:35 EST\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui SIEMPRE voy a hacer un semillerio, independientemente de si en la Bayesian Optimization calculé un semillerio en cada iteración.\n",
    "<br> Entreno un LightGBM para cada semilla,  y guardo el modelo dentro de la carpeta  **modelitos**\n",
    "<br> Intencionalmente en una primera etapá se generan los modelos y graban, y en una segunda etapa se leen eso modelos y se aplican a los datos del futuro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APO controla cuantas veces se repite el modelo, que se usa para promediar ganancias y reportar en la Pseudo Competencia algo razonable\n",
    "<br> El modelo puede ser un LightGBM simple (ksemillerio==1)  o un Ensemble Semillerio( ksemillerio > 1 )\n",
    "<br> Lamentablmente APO necesita utilizar muchas semillas, y eso demanda TIEMPO de corrida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semillerio Final\n",
    "PARAM$train_final$APO <- 100\n",
    "PARAM$train_final$ksemillerio  <- 100\n",
    "\n",
    "PARAM$train_final$cortes <- c(10500, 11000, 11500, 12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valvula de seguridad anti atajos\n",
    "if( PARAM$train_final$APO * PARAM$train_final$ksemillerio  < 100\n",
    "  | PARAM$train_final$APO < 5\n",
    ")  {\n",
    "  # stop(\"No quiera overfitear\")\n",
    "  cat(\"No quiera overfitear\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>974411</li><li>507673</li><li>696271</li><li>281233</li><li>677309</li><li>180647</li><li>251519</li><li>235241</li><li>176213</li><li>162601</li><li>138637</li><li>519551</li><li>807931</li><li>471301</li><li>152063</li><li>823663</li><li>874337</li><li>466201</li><li>206191</li><li>787939</li><li>361327</li><li>320141</li><li>459847</li><li>246833</li><li>208799</li><li>381371</li><li>868327</li><li>745187</li><li>297371</li><li>244147</li><li>775739</li><li>486043</li><li>903163</li><li>228989</li><li>714223</li><li>766943</li><li>838157</li><li>492253</li><li>954757</li><li>698393</li><li>424103</li><li>964637</li><li>581239</li><li>315739</li><li>868379</li><li>589439</li><li>114487</li><li>645131</li><li>794953</li><li>356567</li><li>609821</li><li>660799</li><li>957059</li><li>495629</li><li>227627</li><li>647161</li><li>499327</li><li>671837</li><li>810239</li><li>776219</li><li>205663</li><li>681781</li><li>766739</li><li>671633</li><li>450601</li><li>204583</li><li>822839</li><li>217411</li><li>333071</li><li>823033</li><li>631471</li><li>595073</li><li>139663</li><li>564301</li><li>459749</li><li>713863</li><li>979171</li><li>119569</li><li>935303</li><li>440641</li><li>207187</li><li>907811</li><li>552263</li><li>281839</li><li>990281</li><li>326707</li><li>346739</li><li>451783</li><li>523771</li><li>377129</li><li>783613</li><li>720901</li><li>268843</li><li>349409</li><li>352619</li><li>473353</li><li>847601</li><li>859787</li><li>427241</li><li>365201</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 974411\n",
       "\\item 507673\n",
       "\\item 696271\n",
       "\\item 281233\n",
       "\\item 677309\n",
       "\\item 180647\n",
       "\\item 251519\n",
       "\\item 235241\n",
       "\\item 176213\n",
       "\\item 162601\n",
       "\\item 138637\n",
       "\\item 519551\n",
       "\\item 807931\n",
       "\\item 471301\n",
       "\\item 152063\n",
       "\\item 823663\n",
       "\\item 874337\n",
       "\\item 466201\n",
       "\\item 206191\n",
       "\\item 787939\n",
       "\\item 361327\n",
       "\\item 320141\n",
       "\\item 459847\n",
       "\\item 246833\n",
       "\\item 208799\n",
       "\\item 381371\n",
       "\\item 868327\n",
       "\\item 745187\n",
       "\\item 297371\n",
       "\\item 244147\n",
       "\\item 775739\n",
       "\\item 486043\n",
       "\\item 903163\n",
       "\\item 228989\n",
       "\\item 714223\n",
       "\\item 766943\n",
       "\\item 838157\n",
       "\\item 492253\n",
       "\\item 954757\n",
       "\\item 698393\n",
       "\\item 424103\n",
       "\\item 964637\n",
       "\\item 581239\n",
       "\\item 315739\n",
       "\\item 868379\n",
       "\\item 589439\n",
       "\\item 114487\n",
       "\\item 645131\n",
       "\\item 794953\n",
       "\\item 356567\n",
       "\\item 609821\n",
       "\\item 660799\n",
       "\\item 957059\n",
       "\\item 495629\n",
       "\\item 227627\n",
       "\\item 647161\n",
       "\\item 499327\n",
       "\\item 671837\n",
       "\\item 810239\n",
       "\\item 776219\n",
       "\\item 205663\n",
       "\\item 681781\n",
       "\\item 766739\n",
       "\\item 671633\n",
       "\\item 450601\n",
       "\\item 204583\n",
       "\\item 822839\n",
       "\\item 217411\n",
       "\\item 333071\n",
       "\\item 823033\n",
       "\\item 631471\n",
       "\\item 595073\n",
       "\\item 139663\n",
       "\\item 564301\n",
       "\\item 459749\n",
       "\\item 713863\n",
       "\\item 979171\n",
       "\\item 119569\n",
       "\\item 935303\n",
       "\\item 440641\n",
       "\\item 207187\n",
       "\\item 907811\n",
       "\\item 552263\n",
       "\\item 281839\n",
       "\\item 990281\n",
       "\\item 326707\n",
       "\\item 346739\n",
       "\\item 451783\n",
       "\\item 523771\n",
       "\\item 377129\n",
       "\\item 783613\n",
       "\\item 720901\n",
       "\\item 268843\n",
       "\\item 349409\n",
       "\\item 352619\n",
       "\\item 473353\n",
       "\\item 847601\n",
       "\\item 859787\n",
       "\\item 427241\n",
       "\\item 365201\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 974411\n",
       "2. 507673\n",
       "3. 696271\n",
       "4. 281233\n",
       "5. 677309\n",
       "6. 180647\n",
       "7. 251519\n",
       "8. 235241\n",
       "9. 176213\n",
       "10. 162601\n",
       "11. 138637\n",
       "12. 519551\n",
       "13. 807931\n",
       "14. 471301\n",
       "15. 152063\n",
       "16. 823663\n",
       "17. 874337\n",
       "18. 466201\n",
       "19. 206191\n",
       "20. 787939\n",
       "21. 361327\n",
       "22. 320141\n",
       "23. 459847\n",
       "24. 246833\n",
       "25. 208799\n",
       "26. 381371\n",
       "27. 868327\n",
       "28. 745187\n",
       "29. 297371\n",
       "30. 244147\n",
       "31. 775739\n",
       "32. 486043\n",
       "33. 903163\n",
       "34. 228989\n",
       "35. 714223\n",
       "36. 766943\n",
       "37. 838157\n",
       "38. 492253\n",
       "39. 954757\n",
       "40. 698393\n",
       "41. 424103\n",
       "42. 964637\n",
       "43. 581239\n",
       "44. 315739\n",
       "45. 868379\n",
       "46. 589439\n",
       "47. 114487\n",
       "48. 645131\n",
       "49. 794953\n",
       "50. 356567\n",
       "51. 609821\n",
       "52. 660799\n",
       "53. 957059\n",
       "54. 495629\n",
       "55. 227627\n",
       "56. 647161\n",
       "57. 499327\n",
       "58. 671837\n",
       "59. 810239\n",
       "60. 776219\n",
       "61. 205663\n",
       "62. 681781\n",
       "63. 766739\n",
       "64. 671633\n",
       "65. 450601\n",
       "66. 204583\n",
       "67. 822839\n",
       "68. 217411\n",
       "69. 333071\n",
       "70. 823033\n",
       "71. 631471\n",
       "72. 595073\n",
       "73. 139663\n",
       "74. 564301\n",
       "75. 459749\n",
       "76. 713863\n",
       "77. 979171\n",
       "78. 119569\n",
       "79. 935303\n",
       "80. 440641\n",
       "81. 207187\n",
       "82. 907811\n",
       "83. 552263\n",
       "84. 281839\n",
       "85. 990281\n",
       "86. 326707\n",
       "87. 346739\n",
       "88. 451783\n",
       "89. 523771\n",
       "90. 377129\n",
       "91. 783613\n",
       "92. 720901\n",
       "93. 268843\n",
       "94. 349409\n",
       "95. 352619\n",
       "96. 473353\n",
       "97. 847601\n",
       "98. 859787\n",
       "99. 427241\n",
       "100. 365201\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] 974411 507673 696271 281233 677309 180647 251519 235241 176213 162601\n",
       " [11] 138637 519551 807931 471301 152063 823663 874337 466201 206191 787939\n",
       " [21] 361327 320141 459847 246833 208799 381371 868327 745187 297371 244147\n",
       " [31] 775739 486043 903163 228989 714223 766943 838157 492253 954757 698393\n",
       " [41] 424103 964637 581239 315739 868379 589439 114487 645131 794953 356567\n",
       " [51] 609821 660799 957059 495629 227627 647161 499327 671837 810239 776219\n",
       " [61] 205663 681781 766739 671633 450601 204583 822839 217411 333071 823033\n",
       " [71] 631471 595073 139663 564301 459749 713863 979171 119569 935303 440641\n",
       " [81] 207187 907811 552263 281839 990281 326707 346739 451783 523771 377129\n",
       " [91] 783613 720901 268843 349409 352619 473353 847601 859787 427241 365201"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "PARAM$train_final$semillas <- sample(primos)[seq( PARAM$train_final$ksemillerio*PARAM$train_final$APO )]\n",
    "PARAM$train_final$semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filas 437055 columnas 1241 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-07 21:08:58 EST\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dejo los datos en formato LightGBM\n",
    "dtrain_final <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train_final[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train_final[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "cat(\"filas\", nrow(dtrain_final), \"columnas\", ncol(dtrain_final), \"\\n\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "xElu4s5W4rX7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-07 21:08:58 EST\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# genero los modelitos\n",
    "\n",
    "param_completo <- copy( PARAM$train_final$param_mejores)\n",
    "\n",
    "for( sem in PARAM$train_final$semillas ) {\n",
    "\n",
    "  arch_modelo <- paste0(PARAM$paths$models, \"/mod_\", sem, \".txt\")\n",
    "  if( !file.exists( arch_modelo ) )\n",
    "  {\n",
    "    param_completo$seed <- sem\n",
    "\n",
    "    modelito <- lgb.train(\n",
    "      data= dtrain_final,\n",
    "      param= param_completo\n",
    "    )\n",
    "\n",
    "    lgb.save( modelito, filename= arch_modelo)\n",
    "    rm(modelito)\n",
    "    gc()\n",
    "  }\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace el predict() del modelo en los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset de future, donde en este caso estoy haciendo testing\n",
    "dfuture <- dataset[foto_mes %in% PARAM$train_final$future ]\n",
    "mfuture <- data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
    "\n",
    "dfuture[, ganancia := ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mganancias <- matrix( nrow=PARAM$train_final$APO, ncol= length(PARAM$train_final$cortes) )\n",
    "\n",
    "if( file.exists(\"prediccion.txt\") )\n",
    "  file.remove(\"prediccion.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-07 21:17:29 EST\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# aplico el modelo a los datos del future\n",
    "\n",
    "for( vapo in seq(PARAM$train_final$APO) ) {\n",
    "  # inicializacion en CERO\n",
    "  vpred_acum <- rep(0.0, nrow(dfuture))\n",
    "  qacumulados <- 0\n",
    "\n",
    "  desde <- 1 + (vapo-1)*PARAM$train_final$ksemillerio\n",
    "  hasta <- desde + PARAM$train_final$ksemillerio - 1\n",
    "  semillas <- PARAM$train_final$semillas[desde:hasta]\n",
    "\n",
    "  for( sem in semillas ) {\n",
    "\n",
    "    arch_modelo <- paste0(PARAM$paths$models, \"/mod_\", sem, \".txt\")\n",
    "    if( file.exists( arch_modelo ) )\n",
    "    {\n",
    "      modelo_final <- lgb.load(arch_modelo) # leo del disco\n",
    "      # hago el predict() y acumulo\n",
    "      vpred_acum <- vpred_acum + predict(modelo_final, mfuture)\n",
    "      qacumulados <- qacumulados + 1\n",
    "      rm(modelo_final)\n",
    "      gc()\n",
    "    }\n",
    "  }\n",
    "\n",
    "  if( qacumulados > 0 ) {\n",
    "    vpred_acum <- vpred_acum / qacumulados  # paso a probabildiad\n",
    "    # tabla de prediccion, puede ser util para futuros ensembles\n",
    "    #  ya que le modelo ganador va a ser un ensemble de LightGBMs\n",
    "\n",
    "    tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes, ganancia)]\n",
    "    tb_prediccion[, meta_modelo := vapo]\n",
    "    tb_prediccion[, prob := vpred_acum ]\n",
    "    setorder( tb_prediccion, -prob )\n",
    "    tb_prediccion[, gan_acum := cumsum(ganancia)]\n",
    "    tb_prediccion[, ganancia := NULL ]\n",
    "\n",
    "    # acumulo las ganancias\n",
    "    for( icor in seq(length(PARAM$train_final$cortes)) ){\n",
    "      mganancias[ vapo, icor ] <- tb_prediccion[ PARAM$train_final$cortes[icor], gan_acum ]\n",
    "    }\n",
    "\n",
    "    # grabo las probabilidades del modelo\n",
    "    fwrite(tb_prediccion,\n",
    "      file= \"prediccion.txt\",\n",
    "      sep= \"\\t\",\n",
    "      append= TRUE\n",
    "    )\n",
    "\n",
    "    rm(tb_prediccion)\n",
    "    gc()\n",
    "  }\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 10 × 4 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>407600000</td><td>411200000</td><td>406800000</td><td>404000000</td></tr>\n",
       "\t<tr><td>407600000</td><td>406400000</td><td>408400000</td><td>407200000</td></tr>\n",
       "\t<tr><td>410800000</td><td>408800000</td><td>406800000</td><td>405600000</td></tr>\n",
       "\t<tr><td>407600000</td><td>407200000</td><td>403600000</td><td>403200000</td></tr>\n",
       "\t<tr><td>411600000</td><td>411200000</td><td>407600000</td><td>407200000</td></tr>\n",
       "\t<tr><td>406000000</td><td>402400000</td><td>404400000</td><td>405600000</td></tr>\n",
       "\t<tr><td>407600000</td><td>412000000</td><td>408400000</td><td>408000000</td></tr>\n",
       "\t<tr><td>405200000</td><td>407200000</td><td>409200000</td><td>404000000</td></tr>\n",
       "\t<tr><td>407600000</td><td>405600000</td><td>407600000</td><td>404800000</td></tr>\n",
       "\t<tr><td>408400000</td><td>409600000</td><td>407600000</td><td>403200000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 10 × 4 of type dbl\n",
       "\\begin{tabular}{llll}\n",
       "\t 407600000 & 411200000 & 406800000 & 404000000\\\\\n",
       "\t 407600000 & 406400000 & 408400000 & 407200000\\\\\n",
       "\t 410800000 & 408800000 & 406800000 & 405600000\\\\\n",
       "\t 407600000 & 407200000 & 403600000 & 403200000\\\\\n",
       "\t 411600000 & 411200000 & 407600000 & 407200000\\\\\n",
       "\t 406000000 & 402400000 & 404400000 & 405600000\\\\\n",
       "\t 407600000 & 412000000 & 408400000 & 408000000\\\\\n",
       "\t 405200000 & 407200000 & 409200000 & 404000000\\\\\n",
       "\t 407600000 & 405600000 & 407600000 & 404800000\\\\\n",
       "\t 408400000 & 409600000 & 407600000 & 403200000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 10 × 4 of type dbl\n",
       "\n",
       "| 407600000 | 411200000 | 406800000 | 404000000 |\n",
       "| 407600000 | 406400000 | 408400000 | 407200000 |\n",
       "| 410800000 | 408800000 | 406800000 | 405600000 |\n",
       "| 407600000 | 407200000 | 403600000 | 403200000 |\n",
       "| 411600000 | 411200000 | 407600000 | 407200000 |\n",
       "| 406000000 | 402400000 | 404400000 | 405600000 |\n",
       "| 407600000 | 412000000 | 408400000 | 408000000 |\n",
       "| 405200000 | 407200000 | 409200000 | 404000000 |\n",
       "| 407600000 | 405600000 | 407600000 | 404800000 |\n",
       "| 408400000 | 409600000 | 407600000 | 403200000 |\n",
       "\n"
      ],
      "text/plain": [
       "      [,1]      [,2]      [,3]      [,4]     \n",
       " [1,] 407600000 411200000 406800000 404000000\n",
       " [2,] 407600000 406400000 408400000 407200000\n",
       " [3,] 410800000 408800000 406800000 405600000\n",
       " [4,] 407600000 407200000 403600000 403200000\n",
       " [5,] 411600000 411200000 407600000 407200000\n",
       " [6,] 406000000 402400000 404400000 405600000\n",
       " [7,] 407600000 412000000 408400000 408000000\n",
       " [8,] 405200000 407200000 409200000 404000000\n",
       " [9,] 407600000 405600000 407600000 404800000\n",
       "[10,] 408400000 409600000 407600000 403200000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mganancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOt4eG_55ltv",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tomó la decisión de enviar a los 11000 registros con mayor probabilidad de POS={\"BAJA+1\",\"BAJA+\"}\n",
    "<br> esto se determinó en forma artesanal analizando meses anterior\n",
    "<br> esta es una muy importante decisión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genero archivos con los  \"envios\" mejores\n",
    "dir.create(\"kaggle\", showWarnings=FALSE)\n",
    "\n",
    "tb_prediccion <- fread(\"prediccion.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "gWW3tatE12je"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-07 21:17:31 EST\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# genero archivos de fantasia, que NO son el que voy a subir a la Pseudo Competencia Kaggle\n",
    "envios <- 11000\n",
    "\n",
    "for( vapo in seq(PARAM$train_final$APO) ) {\n",
    "  if( tb_prediccion[meta_modelo==vapo, .N] > 0 ) {\n",
    "    tb_pred <- tb_prediccion[meta_modelo==vapo]\n",
    "    setorder( tb_pred, -prob )\n",
    "    tb_pred[, Predicted := 0L] # seteo inicial a 0\n",
    "    tb_pred[1:envios, Predicted := 1L] # marco los primeros\n",
    "\n",
    "    archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", vapo, \"_\", envios, \".csv\")\n",
    "\n",
    "    # grabo el archivo\n",
    "    fwrite(tb_pred[, list(numero_de_cliente, Predicted)],\n",
    "      file= archivo_kaggle,\n",
    "      sep= \",\"\n",
    "    )\n",
    "\n",
    "    rm( tb_pred )\n",
    "    gc()\n",
    "  }\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subida a Pseudo Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui viene la verdadera magia de  APO = A Prueba Overfiteres\n",
    "<br>Se sube un submit a la Pseudo Competencia Kaggle cuya ganancia coincide casi exactamente con la ganancia MEDIA , promediada  APO veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "colmedias <- colMeans( mganancias, na.rm=TRUE )\n",
    "mcorte_mejor <- max(colmedias, na.rm=TRUE)\n",
    "icorte_mejor <- which.max( colmedias )\n",
    "corte_mejor <- PARAM$train_final$cortes[icorte_mejor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl <- as.data.table( as.list( colmedias ) )\n",
    "colnames(tbl) <- paste0( \"e\", PARAM$train_final$cortes )\n",
    "tbl[, experimento := PARAM$experimento ]\n",
    "\n",
    "dir.create(exp_gral, showWarnings=FALSE)\n",
    "fwrite( tbl,\n",
    "  file= paste0( PARAM$paths$apo, \"/tb_experimentos.txt\"),\n",
    "  sep= \"\\t\",\n",
    "  append= TRUE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames( mganancias ) <- paste0( \"e\", PARAM$train_final$cortes )\n",
    "tbl_local <- as.data.table( mganancias )\n",
    "\n",
    "fwrite( tbl_local,\n",
    "  file= \"tb_apo.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "408160000"
      ],
      "text/latex": [
       "408160000"
      ],
      "text/markdown": [
       "408160000"
      ],
      "text/plain": [
       "[1] 408160000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "10032"
      ],
      "text/latex": [
       "10032"
      ],
      "text/markdown": [
       "10032"
      ],
      "text/plain": [
       "[1] 10032"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 1 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>numero_de_cliente</th><th scope=col>foto_mes</th><th scope=col>meta_modelo</th><th scope=col>prob</th><th scope=col>gan_acum</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1209477280</td><td>202106</td><td>1</td><td>0.113957</td><td>408160000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " numero\\_de\\_cliente & foto\\_mes & meta\\_modelo & prob & gan\\_acum\\\\\n",
       " <int> & <int> & <int> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 1209477280 & 202106 & 1 & 0.113957 & 408160000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 5\n",
       "\n",
       "| numero_de_cliente &lt;int&gt; | foto_mes &lt;int&gt; | meta_modelo &lt;int&gt; | prob &lt;dbl&gt; | gan_acum &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1209477280 | 202106 | 1 | 0.113957 | 408160000 |\n",
       "\n"
      ],
      "text/plain": [
       "  numero_de_cliente foto_mes meta_modelo prob     gan_acum \n",
       "1 1209477280        202106   1           0.113957 408160000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "icerca <- which.min(  abs( tb_prediccion$gan_acum - mcorte_mejor ) )\n",
    "vmodelo <- tb_prediccion[ icerca, meta_modelo ]\n",
    "tb_pred <- tb_prediccion[meta_modelo==vmodelo]\n",
    "\n",
    "mcorte_mejor\n",
    "icerca\n",
    "tb_prediccion[ icerca]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "10032"
      ],
      "text/latex": [
       "10032"
      ],
      "text/markdown": [
       "10032"
      ],
      "text/plain": [
       "[1] 10032"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "icerca <- which.min(  abs( tb_pred$gan_acum - mcorte_mejor ) )\n",
    "icerca"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
